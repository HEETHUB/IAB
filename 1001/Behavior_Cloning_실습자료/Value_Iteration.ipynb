{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Value_Iteration",
      "provenance": [],
      "collapsed_sections": [
        "yp9q3Tgmu454"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTnRy6ffpeVi"
      },
      "source": [
        "# Value Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEIEtBKBpp4W"
      },
      "source": [
        "## Import library & Create modified environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQe66rx-BFcj"
      },
      "source": [
        "import gym\n",
        "from gym.envs.registration import register\n",
        "# DO NOT RUN TWICE OR YOU'LL GET AN ERROR => SOLVE BY RESTARTING RUNTIME (\"Runtime\" -> \"Restart Runtime\")\n",
        "register(id='FrozenLakeDeterministic-v0', \n",
        "         entry_point='gym.envs.toy_text:FrozenLakeEnv', \n",
        "         kwargs={'map_name': '4x4', \n",
        "                 'is_slippery': False}, \n",
        "         max_episode_steps=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnobrulop7fV"
      },
      "source": [
        "## Modified FrozenLake-v0's MDP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFt9GFNXB-df"
      },
      "source": [
        "env = gym.make('FrozenLakeDeterministic-v0')\n",
        "print(\"Observation space:\\t{}\".format(env.observation_space))\n",
        "print(\"Action space:\\t\\t{}\".format(env.action_space))\n",
        "\n",
        "print('-'*20)\n",
        "\n",
        "num_states = env.nS\n",
        "print(\"Number of states: {}\".format(num_states))\n",
        "num_actions = env.nA\n",
        "print(\"Number of actions: {}\".format(num_actions))\n",
        "\n",
        "print('-'*20)\n",
        "\n",
        "all_states = [i for i in range(num_states)]\n",
        "print(\"All states: {}\".format(all_states))\n",
        "all_actions = [i for i in range(num_actions)]\n",
        "print(\"All actions: {}\".format(all_actions))\n",
        "\n",
        "print('-'*20)\n",
        "\n",
        "probability_matrix = env.P\n",
        "print(\"Transition matrix:\")\n",
        "print(env.P)\n",
        "print(\"Transition matrix with current state = 0\")\n",
        "print(env.P[0])\n",
        "print(\"Transition matrix with current state = 0, action = 0\")\n",
        "print(env.P[0][0])\n",
        "print(\"Note that this environment is deterministic! That is, for a given state and action, the next state is determined!\")\n",
        "\n",
        "print('-'*20)\n",
        "print(\"4x4 map\")\n",
        "obs = env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGciq9PBqKBr"
      },
      "source": [
        "## Random Action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNdGP6jFBjjA"
      },
      "source": [
        "env = gym.make('FrozenLakeDeterministic-v0')\n",
        "obs = env.reset()\n",
        "total_reward = 0\n",
        "num_steps = 0\n",
        "while True:\n",
        "    print('#'*10)\n",
        "    print(\"Timestep {}\".format(num_steps))\n",
        "    print(\"Observation: {}\".format(obs))\n",
        "    print('#'*10)\n",
        "    env.render()\n",
        "    random_action = env.action_space.sample()\n",
        "    print('#'*10)\n",
        "    print(\"Action: {}\".format(random_action))\n",
        "    print('#'*10)\n",
        "    obs, reward, done, info = env.step(random_action)\n",
        "    total_reward += reward\n",
        "    num_steps += 1\n",
        "    print('-'*15)\n",
        "    if done is True:\n",
        "        print(\"Done!\")\n",
        "        break\n",
        "env.close()\n",
        "print(\"Total reward of {:.2f} for {} number of steps\".format(total_reward, num_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja-SraXvqP0c"
      },
      "source": [
        "## Value Iteration Algorithm\n",
        "For all states, <br>\n",
        "$V_{0}(s)=0$<br>\n",
        "$V_{t+1}(s)=R(s)+\\gamma\\max_{a\\in A(s)}\\sum_{s'}P(s'|s, a)V_{t}(s')$<br>\n",
        "NOTE: In this modified environment, $P(s'|s,a)=1$ for all states and actions $s,a$<br>\n",
        "Thus, for this special case, we can simply use the following update:<br>\n",
        "$V_{t+1}(s)=R(s)+\\gamma\\max_{a\\in A(s)}V_{t}(s'(s,a))$<br>\n",
        ", where $s'$ is simply the next state returned given some state and action pair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8xOtqD_E0iQ"
      },
      "source": [
        "# Initialize values and optimal policy for all states\n",
        "values = {}\n",
        "optimal_policy = {}\n",
        "for state in all_states:\n",
        "    values[state] = 0\n",
        "    optimal_policy[state] = None\n",
        "\n",
        "print(\"Current value table:\")\n",
        "print('\\t', values)\n",
        "print(\"Current optimal policy table:\")\n",
        "print('\\t', optimal_policy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJAdvUFfHKg5"
      },
      "source": [
        "# Value iteration\n",
        "env = gym.make('FrozenLakeDeterministic-v0')\n",
        "env.reset()\n",
        "\n",
        "num_iters = 1000\n",
        "gamma = 0.99\n",
        "\n",
        "from copy import deepcopy\n",
        "import time\n",
        "import math\n",
        "\n",
        "start_time = time.time()\n",
        "for it in range(num_iters):\n",
        "    old_values = deepcopy(values)\n",
        "    for state in all_states:\n",
        "        best_value = -math.inf\n",
        "        best_action = None\n",
        "        for action in all_actions:\n",
        "            ##### TO IMPLEMENT #####\n",
        "            prob, next_state, reward, done = env.P[state][action][0]\n",
        "            new_value = \n",
        "            if new_value > best_value:\n",
        "                best_value = \n",
        "                best_action = \n",
        "                values[state] = \n",
        "                optimal_policy[state] = \n",
        "            ########################\n",
        "    if (it+1) % 100 == 0:\n",
        "        time_taken = time.time() - start_time\n",
        "        print(\"Iteration: {}/{} \\t\\t{:.4f}s\".format(it+1, num_iters, time_taken))\n",
        "\n",
        "print('-'*40)\n",
        "print(\"Current value table:\")\n",
        "print('\\t', values)\n",
        "print(\"Current optimal policy table:\")\n",
        "print('\\t', optimal_policy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PegeWgI4Kcrj"
      },
      "source": [
        "# Evaluation\n",
        "env = gym.make('FrozenLakeDeterministic-v0')\n",
        "state = env.reset()\n",
        "total_reward = 0\n",
        "num_steps = 0\n",
        "while True:\n",
        "    print('#'*10)\n",
        "    print(\"Timestep {}\".format(num_steps))\n",
        "    print(\"Observation: {}\".format(obs))\n",
        "    print('#'*10)\n",
        "    env.render()\n",
        "    optimal_action = optimal_policy[state]\n",
        "    print('#'*10)\n",
        "    print(\"Optimal action: {}\".format(optimal_action))\n",
        "    print('#'*10)\n",
        "    state, reward, done, info = env.step(optimal_action)\n",
        "    total_reward += reward\n",
        "    num_steps += 1\n",
        "    print('-'*15)\n",
        "    if done is True:\n",
        "        print(\"Done!\")\n",
        "        break\n",
        "env.close()\n",
        "print(\"Total reward of {:.2f} for {} number of steps\".format(total_reward, num_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp9q3Tgmu454"
      },
      "source": [
        "## (Optional) Solve bigger map!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6OI1ZHPMKNk"
      },
      "source": [
        "# Try with the following map!\n",
        "random_map = gym.envs.toy_text.frozen_lake.generate_random_map(size=64)\n",
        "env = gym.make(\"FrozenLakeDeterministic-v0\", desc=random_map)\n",
        "env.reset()\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}