{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnKXszGIuTo7"
   },
   "source": [
    "# IoT·인공지능·빅데이터 개론 및 실습 (2021년도, 2학기, M2177.004900_001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KubnO2egumeN"
   },
   "source": [
    "##9/10 Logistic Regerssion & Neural Network with Scikit-Learn\n",
    "\n",
    "Adapted by Seonwoo Min from the \"An Introduction to Machine Learning with Scikit-learn\" tutorial (http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
    "\n",
    "In this excercise, we will cover:\n",
    "\n",
    "* Loading an example dataset & preprocessing\n",
    "* Logistic regression & neural network models in scikit-learn\n",
    "* Model training & prediction & evaluation\n",
    "* Model save & load\n",
    "* Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jCc3nd2uTpB"
   },
   "source": [
    "## 1. Loading an example dataset & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oXR0qyJ-uTpC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5FfgysTkuTpC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  (1797, 64)\n",
      "Label: (1797,)\n",
      "Class: 0  Number: 178\n",
      "Class: 1  Number: 182\n",
      "Class: 2  Number: 177\n",
      "Class: 3  Number: 183\n",
      "Class: 4  Number: 181\n",
      "Class: 5  Number: 182\n",
      "Class: 6  Number: 181\n",
      "Class: 7  Number: 179\n",
      "Class: 8  Number: 174\n",
      "Class: 9  Number: 180\n"
     ]
    }
   ],
   "source": [
    "# Data shape & statistics\n",
    "print(\"Data: \", data['data'].shape)\n",
    "print(\"Label:\", data['target'].shape)\n",
    "\n",
    "# Print the number of samples for each class\n",
    "import numpy as np\n",
    "#################### To Do #################################\n",
    "for c in range(10):\n",
    "    print('Class:', c,' Number:', np.sum(data['target'] == c) )\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oG1dHr4CuTpC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Data Visaulization\n",
    "#############################################################\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#################### To Do #################################\n",
    "# Hint: plt.imshow(data['data'][i].reshape(8,8), cmap=plt.cm.gray_r)\n",
    "for c in range(10):\n",
    "    i = 0\n",
    "    while(1):\n",
    "        if data['target'][i] == c :\n",
    "            plt.subplot(2, 5, c+1) # 2 row, 5 column으로 이루어진 subplot\n",
    "            plt.axis('off')\n",
    "            plt.imshow(data['data'][i].reshape(8,8), cmap=plt.cm.gray_r)\n",
    "            plt.title('Class %d:' % c)\n",
    "            break\n",
    "        i += 1\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5aeX7JqhuTpD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64)\n",
      "(1697, 64)\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# 1st Preprocessing\n",
    "# Use the first 10 samples in each class as test data\n",
    "# Use the others as training data\n",
    "#############################################################\n",
    "\n",
    "#################### To Do #################################\n",
    "test_indexes, train_indexes = [], []\n",
    "num = [0] * 10\n",
    "for i in range(len(data['target'])):\n",
    "    if num[data['target'][i]] < 10: test_indexes.append(i)\n",
    "    else : train_indexes.append(i)\n",
    "    num[data['target'][i]] += 1\n",
    "\n",
    "test_data, test_target = data['data'][test_indexes], data['target'][test_indexes]\n",
    "train_data, train_target = data['data'][train_indexes], data['target'][train_indexes]\n",
    "############################################################\n",
    "\n",
    "print(test_data.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ie567PVduTpD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 64)\n",
      "(340, 64)\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# 2nd Preprocessing\n",
    "# Let's use only 2 and 3 for binary classification\n",
    "#############################################################\n",
    "\n",
    "#################### To Do #################################\n",
    "test_data23, test_target23 = test_data[(test_target == 2) ^ (test_target == 3)], test_target[(test_target == 2) ^ (test_target == 3)]\n",
    "train_data23, train_target23 = train_data[(train_target == 2) ^ (train_target == 3)], train_target[(train_target == 2) ^ (train_target == 3)]\n",
    "############################################################\n",
    "# ^ = or operation\n",
    "\n",
    "print(test_data23.shape)\n",
    "print(train_data23.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOtAaDjbuTpD"
   },
   "source": [
    "## 2. Logistic regression & neural network models in scikit-learn\n",
    "\n",
    "For full documentations refer to the following links: <br>\n",
    "Logistic Regression: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html <br>\n",
    "Neural network: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6Ci9vgU5uTpE"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "LR = LogisticRegression(max_iter=1000, solver='sag')\n",
    "NN = MLPClassifier(hidden_layer_sizes=(10), activation='relu', learning_rate_init=0.01, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmBMZFuKuTpE"
   },
   "source": [
    "## 3. Model training & prediction & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Etwr4biEuTpE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_target     : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 2 3 2 3]\n",
      "test_prediction : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 2 3 2 3]\n",
      "train_acc : 0.9941176470588236\n",
      "test_acc  : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heetaecho/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Logistic regression model\n",
    "#############################################################\n",
    "# Training\n",
    "LR = LogisticRegression(max_iter=1, solver='sag')\n",
    "LR.fit(train_data23, train_target23) # logistic regression model이 data에 맞춰 학습\n",
    "\n",
    "\n",
    "# Prediction\n",
    "train_predict23 = LR.predict(train_data23)\n",
    "test_predict23 = LR.predict(test_data23)\n",
    "print(\"test_target     :\", test_target23)\n",
    "print(\"test_prediction :\", test_predict23)\n",
    "\n",
    "#################### To Do #################################\n",
    "# Evaluation\n",
    "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
    "test_acc23 = np.sum(test_target23 == test_predict23) / len(test_target23)\n",
    "############################################################\n",
    "\n",
    "print(\"train_acc :\", train_acc23)\n",
    "print(\"test_acc  :\", test_acc23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "a6DMzuxRuTpF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_target     : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 2 3 2 3]\n",
      "test_prediction : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 2 2 2 3]\n",
      "train_acc : 0.8264705882352941\n",
      "test_acc  : 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heetaecho/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Neural network model\n",
    "#############################################################\n",
    "# https://machfam.com/16450\n",
    "#################### To Do #################################\n",
    "# Training\n",
    "NN = MLPClassifier(hidden_layer_sizes=(10), activation='relu', learning_rate_init=0.01, max_iter=1)\n",
    "NN.fit(train_data23, train_target23)\n",
    "\n",
    "# Prediction\n",
    "train_predict23 = NN.predict(train_data23)\n",
    "test_predict23 = NN.predict(test_data23)\n",
    "print(\"test_target     :\", test_target23)\n",
    "print(\"test_prediction :\", test_predict23)\n",
    "\n",
    "# Evaluation\n",
    "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
    "test_acc23= np.sum(test_target23 == test_predict23) / len(test_target23)\n",
    "print(\"train_acc :\", train_acc23)\n",
    "print(\"test_acc  :\", test_acc23)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCiuG6zruTpF"
   },
   "source": [
    "## 4. Model save & load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "OGiSsaIKuTpF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_target     : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 2 3 2 3]\n",
      "test_prediction : [2 3 2 3 2 3 3 2 2 2 2 3 3 3 3 2 2 2 2 3]\n",
      "train_acc : 0.8264705882352941\n",
      "test_acc  : 0.95\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "    \n",
    "# save\n",
    "joblib.dump(NN, 'models/NN23.joblib') \n",
    "#joblib.dump(LR, 'modesl/LR23.joblib')\n",
    "\n",
    "# load\n",
    "NN_load = joblib.load('models/NN23.joblib') \n",
    "#LR_load = joblib.load('modesl/LR23.joblib')\n",
    "\n",
    "#################### To Do #################################\n",
    "# Prediction\n",
    "train_predict23 = NN_load.predict(train_data23)\n",
    "test_predict23 = NN_load.predict(test_data23)\n",
    "print(\"test_target     :\", test_target23)\n",
    "print(\"test_prediction :\", test_predict23)\n",
    "\n",
    "# Evaluation\n",
    "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
    "test_acc23= np.sum(test_target23 == test_predict23) / len(test_target23)\n",
    "print(\"train_acc :\", train_acc23)\n",
    "print(\"test_acc  :\", test_acc23)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMb5E4hMuTpF"
   },
   "source": [
    "## 5. Homework\n",
    "Now it's your job to experiment with models and achieve higher accuracy on the  **<font color=red>on the entire dataset</font>**. <br>\n",
    "Try different hyperparameter configurations and save the final model as \"final_model.joblib\" <br>\n",
    "Submit the current **notebook file and the saved final model** on ETL.\n",
    "* Maximum 10 points for >= 97% accuracy on the test set\n",
    "* Maximum 8 points for >= 96% accuracy on the test set\n",
    "* Maximum 6 points for >= 95% accuracy on the test set\n",
    "* Maximum 4 points for >= 94% accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "id": "0NA25EGYuTpG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/NN.joblib']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Try different hyperparameters\n",
    "# Final model training\n",
    "#############################################################\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#################### To Do #################################\n",
    "\n",
    "NN = MLPClassifier(hidden_layer_sizes=(200, 200, 200), activation='relu', learning_rate_init=0.001, max_iter=1500)\n",
    "NN.fit(train_data, train_target)\n",
    "\n",
    "# Save \n",
    "import joblib\n",
    "joblib.dump(NN, 'models/NN.joblib')\n",
    "\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "id": "rQud1OhYuTpG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_target     : [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 9 5 5 6 5 0\n",
      " 9 8 9 8 4 1 7 7 3 5 1 0 0 2 2 7 8 2 0 1 2 6 3 3 7 3 3 4 6 6 6 4 9 1 5 0 9\n",
      " 5 2 8 2 0 1 7 6 3 2 1 7 4 6 3 1 9 7 8 4 4 5 9 4 8 8]\n",
      "test_prediction : [0 1 2 3 4 9 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 9 5 5 6 5 0\n",
      " 5 8 9 8 4 1 7 7 3 5 1 0 0 2 2 7 8 2 0 1 2 6 3 3 7 3 3 4 6 6 6 4 9 1 5 0 9\n",
      " 5 2 8 2 0 1 7 6 3 2 1 7 4 6 3 1 9 7 8 4 4 5 9 4 8 8]\n",
      "train_acc : 1.0\n",
      "test_acc  : 0.98\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Final model test\n",
    "# Load the final model and obatin the test accuracy\n",
    "#############################################################\n",
    "\n",
    "# Load \n",
    "NN_load = joblib.load('models/NN.joblib')\n",
    "\n",
    "#################### To Do #################################\n",
    "\n",
    "train_predict = NN_load.predict(train_data)\n",
    "test_predict = NN_load.predict(test_data)\n",
    "print(\"test_target     :\", test_target)\n",
    "print(\"test_prediction :\", test_predict)\n",
    "\n",
    "# Evaluation\n",
    "train_acc = np.sum(train_target == train_predict) / len(train_target)\n",
    "test_acc= np.sum(test_target == test_predict) / len(test_target)\n",
    "print(\"train_acc :\", train_acc)\n",
    "print(\"test_acc  :\", test_acc)\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-8CmzNhuTpG"
   },
   "source": [
    "\n",
    "### Describe what you did here\n",
    "In this cell you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your model.\n",
    "* Maximum 10 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0NbdXqzx47b"
   },
   "source": [
    "작성자 학번, 성함 (**반드시 작성해주세요**)\n",
    "\n",
    "학번: 2013-10432\n",
    "\n",
    "이름: 조희태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6R7BMd5YuTpG"
   },
   "source": [
    "_Tell us here_\n",
    "\n",
    "(hidden_layer_sizes=(10, 10), activation='relu', learning_rate_init=0.01, max_iter=100)으로 시작해보았습니다. 하지만 이 정도의 값으로는 정확도가 0.9 이상으로 올라가질 않아 우선적으로 hidden layer size를 (20, 20), (30, 30) 등으로 차차 늘려가다가 실습 수업 시간에 '하나의 hidden layer에 뉴런을 많이 쌓는 것보다 여러 hidden layer에 뉴런을 조금씩 쌓는게 좋더라'는 말씀이 기억이 나 최종적으로 (200, 200, 200)으로 값을 고정시켰습니다. 이후 learning rate를 0.001로 줄여 한 epoch마다 줄어드는 step_size를 확 낮춘 후 iteration을 대신 1000 이상으로 늘렸더니 정확도가 0.94 이상으로 안정적으로 유지되었고 최종적으로 98%의 정확도를 도출하였습니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KubnO2egumeN",
    "6jCc3nd2uTpB",
    "DOtAaDjbuTpD",
    "KmBMZFuKuTpE",
    "WCiuG6zruTpF"
   ],
   "name": "Logistic_Regression_and_Neural_Network_with_Scikit-Learn_Distribution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
